{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df.drop('id',axis=1)\n",
    "y = df['target']\n",
    "X = df.drop('target',axis=1)\n",
    "test = pd.read_csv('test.csv')\n",
    "test.drop('id',axis=1,inplace=True)\n",
    "X_mean = X.mean(axis=1)\n",
    "X['mean']  = X_mean\n",
    "test_mean = test.mean(axis=1)\n",
    "test['mean'] = test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 19750\n"
     ]
    }
   ],
   "source": [
    "features = [ '16', '33', '43', '45', '52', '63', '65', '73', '90', '91', '117', '133', '134', '149', '189', '199', '217', '237', '258', '295']\n",
    "X1 = X[features]\n",
    "test = test[features]\n",
    "print(len(X1), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['random_state'] = 0\n",
    "params['n_jobs'] = -1\n",
    "params['C'] = 0.126\n",
    "params['penalty'] = 'l1'\n",
    "params['class_weight'] = 'balance'\n",
    "params['solver'] = 'saga'\n",
    "best = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X1, y, best):\n",
    "    folds = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 20, random_state = 0)\n",
    "    oof =  np.zeros(len(X1))\n",
    "    clfs = []\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X1, y)):\n",
    "            #print('--- Fold {} started at {}'.format(n_fold, time.ctime()))\n",
    "\n",
    "            train_x, train_y = X1.iloc[train_idx], y.iloc[train_idx]\n",
    "            valid_x, valid_y = X1.iloc[valid_idx], y.iloc[valid_idx]\n",
    "\n",
    "            clf = LogisticRegression(**best)\n",
    "            clf.fit(train_x, train_y)\n",
    "            clfs.append(clf)\n",
    "            \n",
    "            oof[valid_idx] += clf.predict_proba(valid_x)[:,1]\n",
    "            \n",
    "    return clfs, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clfs,test):\n",
    "    predictions = np.zeros(len(test))\n",
    "    for c in clfs:\n",
    "        predictions += c.predict_proba(test)[:,1]\n",
    "    predictions = predictions/len(clfs)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8629166666666667"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs, oof = train(X1 ,y, best)\n",
    "roc_auc_score(y, oof/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicitons =  predict(clfs,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('sample_submission (1).csv')\n",
    "result['target'] = predicitons\n",
    "result.to_csv('submission13.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='auc', patience=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 187 samples, validate on 63 samples\n",
      "Epoch 1/290\n",
      "187/187 [==============================] - 1s 6ms/step - loss: 0.7282 - acc: 0.5775 - val_loss: 0.7223 - val_acc: 0.4921\n",
      "Epoch 2/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.7446 - acc: 0.5722 - val_loss: 0.7178 - val_acc: 0.4921\n",
      "Epoch 3/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6694 - acc: 0.5829 - val_loss: 0.7131 - val_acc: 0.4921\n",
      "Epoch 4/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.7346 - acc: 0.5989 - val_loss: 0.7089 - val_acc: 0.4921\n",
      "Epoch 5/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.7129 - acc: 0.6524 - val_loss: 0.7049 - val_acc: 0.5079\n",
      "Epoch 6/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.7328 - acc: 0.5775 - val_loss: 0.7005 - val_acc: 0.5079\n",
      "Epoch 7/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.7239 - acc: 0.6203 - val_loss: 0.6966 - val_acc: 0.5079\n",
      "Epoch 8/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.7411 - acc: 0.5615 - val_loss: 0.6928 - val_acc: 0.5079\n",
      "Epoch 9/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.6992 - acc: 0.6203 - val_loss: 0.6893 - val_acc: 0.5079\n",
      "Epoch 10/290\n",
      "187/187 [==============================] - 0s 38us/step - loss: 0.6842 - acc: 0.6096 - val_loss: 0.6866 - val_acc: 0.4921\n",
      "Epoch 11/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6607 - acc: 0.6417 - val_loss: 0.6843 - val_acc: 0.4921\n",
      "Epoch 12/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.7214 - acc: 0.5829 - val_loss: 0.6822 - val_acc: 0.5079\n",
      "Epoch 13/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.6409 - acc: 0.6471 - val_loss: 0.6801 - val_acc: 0.5238\n",
      "Epoch 14/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6329 - acc: 0.6257 - val_loss: 0.6779 - val_acc: 0.5238\n",
      "Epoch 15/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6715 - acc: 0.6471 - val_loss: 0.6759 - val_acc: 0.5238\n",
      "Epoch 16/290\n",
      "187/187 [==============================] - 0s 38us/step - loss: 0.6525 - acc: 0.6471 - val_loss: 0.6741 - val_acc: 0.5238\n",
      "Epoch 17/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6541 - acc: 0.6310 - val_loss: 0.6726 - val_acc: 0.5238\n",
      "Epoch 18/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.6635 - acc: 0.6257 - val_loss: 0.6709 - val_acc: 0.5238\n",
      "Epoch 19/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6415 - acc: 0.6096 - val_loss: 0.6693 - val_acc: 0.5238\n",
      "Epoch 20/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6357 - acc: 0.6524 - val_loss: 0.6677 - val_acc: 0.5238\n",
      "Epoch 21/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.6597 - acc: 0.6150 - val_loss: 0.6663 - val_acc: 0.5238\n",
      "Epoch 22/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6363 - acc: 0.6952 - val_loss: 0.6648 - val_acc: 0.5397\n",
      "Epoch 23/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.6188 - acc: 0.6524 - val_loss: 0.6631 - val_acc: 0.5397\n",
      "Epoch 24/290\n",
      "187/187 [==============================] - 0s 40us/step - loss: 0.6327 - acc: 0.6578 - val_loss: 0.6614 - val_acc: 0.5556\n",
      "Epoch 25/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6388 - acc: 0.5882 - val_loss: 0.6598 - val_acc: 0.5873\n",
      "Epoch 26/290\n",
      " 40/187 [=====>........................] - ETA: 0s - loss: 0.6913 - acc: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kexu\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `auc` which is not available. Available metrics are: val_loss,val_acc,loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 0s 37us/step - loss: 0.6304 - acc: 0.6631 - val_loss: 0.6582 - val_acc: 0.6032\n",
      "Epoch 27/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.6267 - acc: 0.6738 - val_loss: 0.6567 - val_acc: 0.6032\n",
      "Epoch 28/290\n",
      "187/187 [==============================] - 0s 38us/step - loss: 0.6083 - acc: 0.6524 - val_loss: 0.6552 - val_acc: 0.6032\n",
      "Epoch 29/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.5928 - acc: 0.6791 - val_loss: 0.6540 - val_acc: 0.6032\n",
      "Epoch 30/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5942 - acc: 0.6738 - val_loss: 0.6525 - val_acc: 0.6190\n",
      "Epoch 31/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.5968 - acc: 0.6898 - val_loss: 0.6510 - val_acc: 0.6190\n",
      "Epoch 32/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6053 - acc: 0.6524 - val_loss: 0.6494 - val_acc: 0.6190\n",
      "Epoch 33/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.6155 - acc: 0.6684 - val_loss: 0.6477 - val_acc: 0.6190\n",
      "Epoch 34/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6373 - acc: 0.6684 - val_loss: 0.6461 - val_acc: 0.6190\n",
      "Epoch 35/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.6296 - acc: 0.6791 - val_loss: 0.6446 - val_acc: 0.6190\n",
      "Epoch 36/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.5974 - acc: 0.6417 - val_loss: 0.6430 - val_acc: 0.6190\n",
      "Epoch 37/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5798 - acc: 0.6791 - val_loss: 0.6412 - val_acc: 0.6190\n",
      "Epoch 38/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.5915 - acc: 0.6631 - val_loss: 0.6397 - val_acc: 0.6190\n",
      "Epoch 39/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.6031 - acc: 0.6417 - val_loss: 0.6383 - val_acc: 0.6190\n",
      "Epoch 40/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5869 - acc: 0.6471 - val_loss: 0.6367 - val_acc: 0.6190\n",
      "Epoch 41/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.5658 - acc: 0.6791 - val_loss: 0.6351 - val_acc: 0.6190\n",
      "Epoch 42/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.5827 - acc: 0.6738 - val_loss: 0.6334 - val_acc: 0.6190\n",
      "Epoch 43/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5626 - acc: 0.6578 - val_loss: 0.6314 - val_acc: 0.6190\n",
      "Epoch 44/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5904 - acc: 0.6471 - val_loss: 0.6295 - val_acc: 0.6190\n",
      "Epoch 45/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5978 - acc: 0.6791 - val_loss: 0.6277 - val_acc: 0.6349\n",
      "Epoch 46/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.5685 - acc: 0.6684 - val_loss: 0.6259 - val_acc: 0.6508\n",
      "Epoch 47/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5960 - acc: 0.6631 - val_loss: 0.6239 - val_acc: 0.6508\n",
      "Epoch 48/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.5526 - acc: 0.7166 - val_loss: 0.6220 - val_acc: 0.6508\n",
      "Epoch 49/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5599 - acc: 0.6738 - val_loss: 0.6200 - val_acc: 0.6508\n",
      "Epoch 50/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.5444 - acc: 0.6791 - val_loss: 0.6181 - val_acc: 0.6667\n",
      "Epoch 51/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5432 - acc: 0.6952 - val_loss: 0.6162 - val_acc: 0.6667\n",
      "Epoch 52/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.5366 - acc: 0.7005 - val_loss: 0.6144 - val_acc: 0.6667\n",
      "Epoch 53/290\n",
      "187/187 [==============================] - 0s 42us/step - loss: 0.5262 - acc: 0.7059 - val_loss: 0.6125 - val_acc: 0.6667\n",
      "Epoch 54/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.5622 - acc: 0.6417 - val_loss: 0.6106 - val_acc: 0.6825\n",
      "Epoch 55/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5358 - acc: 0.6791 - val_loss: 0.6091 - val_acc: 0.6825\n",
      "Epoch 56/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5343 - acc: 0.7059 - val_loss: 0.6070 - val_acc: 0.6825\n",
      "Epoch 57/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.5435 - acc: 0.6524 - val_loss: 0.6045 - val_acc: 0.6825\n",
      "Epoch 58/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5554 - acc: 0.6952 - val_loss: 0.6019 - val_acc: 0.6825\n",
      "Epoch 59/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5579 - acc: 0.6684 - val_loss: 0.5994 - val_acc: 0.6825\n",
      "Epoch 60/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5500 - acc: 0.7059 - val_loss: 0.5968 - val_acc: 0.6984\n",
      "Epoch 61/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.5237 - acc: 0.6952 - val_loss: 0.5945 - val_acc: 0.7143\n",
      "Epoch 62/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5576 - acc: 0.6791 - val_loss: 0.5922 - val_acc: 0.7143\n",
      "Epoch 63/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.5547 - acc: 0.6524 - val_loss: 0.5899 - val_acc: 0.7143\n",
      "Epoch 64/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5064 - acc: 0.7166 - val_loss: 0.5881 - val_acc: 0.7143\n",
      "Epoch 65/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5272 - acc: 0.7326 - val_loss: 0.5865 - val_acc: 0.7143\n",
      "Epoch 66/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5130 - acc: 0.7540 - val_loss: 0.5846 - val_acc: 0.7143\n",
      "Epoch 67/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5173 - acc: 0.7326 - val_loss: 0.5824 - val_acc: 0.7460\n",
      "Epoch 68/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5144 - acc: 0.7540 - val_loss: 0.5805 - val_acc: 0.7460\n",
      "Epoch 69/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.5107 - acc: 0.7380 - val_loss: 0.5787 - val_acc: 0.7460\n",
      "Epoch 70/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5015 - acc: 0.7112 - val_loss: 0.5771 - val_acc: 0.7460\n",
      "Epoch 71/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5250 - acc: 0.6952 - val_loss: 0.5756 - val_acc: 0.7460\n",
      "Epoch 72/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4715 - acc: 0.7861 - val_loss: 0.5736 - val_acc: 0.7460\n",
      "Epoch 73/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5343 - acc: 0.7166 - val_loss: 0.5715 - val_acc: 0.7460\n",
      "Epoch 74/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.4972 - acc: 0.7166 - val_loss: 0.5693 - val_acc: 0.7302\n",
      "Epoch 75/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.4832 - acc: 0.7326 - val_loss: 0.5672 - val_acc: 0.7460\n",
      "Epoch 76/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4921 - acc: 0.7487 - val_loss: 0.5650 - val_acc: 0.7460\n",
      "Epoch 77/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4894 - acc: 0.7219 - val_loss: 0.5630 - val_acc: 0.7460\n",
      "Epoch 78/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5073 - acc: 0.6791 - val_loss: 0.5615 - val_acc: 0.7460\n",
      "Epoch 79/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4711 - acc: 0.7059 - val_loss: 0.5600 - val_acc: 0.7460\n",
      "Epoch 80/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4903 - acc: 0.7380 - val_loss: 0.5585 - val_acc: 0.7460\n",
      "Epoch 81/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.4959 - acc: 0.7166 - val_loss: 0.5573 - val_acc: 0.7460\n",
      "Epoch 82/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.4872 - acc: 0.7487 - val_loss: 0.5557 - val_acc: 0.7460\n",
      "Epoch 83/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.5138 - acc: 0.7005 - val_loss: 0.5543 - val_acc: 0.7619\n",
      "Epoch 84/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4619 - acc: 0.7594 - val_loss: 0.5530 - val_acc: 0.7619\n",
      "Epoch 85/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4728 - acc: 0.7647 - val_loss: 0.5515 - val_acc: 0.7619\n",
      "Epoch 86/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4452 - acc: 0.7647 - val_loss: 0.5500 - val_acc: 0.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4188 - acc: 0.7754 - val_loss: 0.5486 - val_acc: 0.7619\n",
      "Epoch 88/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4437 - acc: 0.7594 - val_loss: 0.5469 - val_acc: 0.7619\n",
      "Epoch 89/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4507 - acc: 0.7968 - val_loss: 0.5455 - val_acc: 0.7619\n",
      "Epoch 90/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.4449 - acc: 0.7594 - val_loss: 0.5442 - val_acc: 0.7619\n",
      "Epoch 91/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4795 - acc: 0.7487 - val_loss: 0.5422 - val_acc: 0.7619\n",
      "Epoch 92/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.4003 - acc: 0.7540 - val_loss: 0.5406 - val_acc: 0.7460\n",
      "Epoch 93/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4409 - acc: 0.7380 - val_loss: 0.5392 - val_acc: 0.7460\n",
      "Epoch 94/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4315 - acc: 0.7861 - val_loss: 0.5376 - val_acc: 0.7460\n",
      "Epoch 95/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4691 - acc: 0.7968 - val_loss: 0.5361 - val_acc: 0.7460\n",
      "Epoch 96/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.4256 - acc: 0.7273 - val_loss: 0.5342 - val_acc: 0.7460\n",
      "Epoch 97/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4306 - acc: 0.7540 - val_loss: 0.5325 - val_acc: 0.7778\n",
      "Epoch 98/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4364 - acc: 0.7701 - val_loss: 0.5301 - val_acc: 0.7778\n",
      "Epoch 99/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.4165 - acc: 0.7540 - val_loss: 0.5294 - val_acc: 0.7778\n",
      "Epoch 100/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.4219 - acc: 0.7861 - val_loss: 0.5289 - val_acc: 0.7778\n",
      "Epoch 101/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.4152 - acc: 0.7861 - val_loss: 0.5281 - val_acc: 0.7778\n",
      "Epoch 102/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3957 - acc: 0.7861 - val_loss: 0.5265 - val_acc: 0.7778\n",
      "Epoch 103/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.4087 - acc: 0.7861 - val_loss: 0.5252 - val_acc: 0.7778\n",
      "Epoch 104/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.3913 - acc: 0.7594 - val_loss: 0.5232 - val_acc: 0.7778\n",
      "Epoch 105/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4386 - acc: 0.7861 - val_loss: 0.5214 - val_acc: 0.7778\n",
      "Epoch 106/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3718 - acc: 0.7914 - val_loss: 0.5189 - val_acc: 0.7778\n",
      "Epoch 107/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3964 - acc: 0.8021 - val_loss: 0.5181 - val_acc: 0.7778\n",
      "Epoch 108/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.4149 - acc: 0.7540 - val_loss: 0.5172 - val_acc: 0.7619\n",
      "Epoch 109/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3823 - acc: 0.7968 - val_loss: 0.5162 - val_acc: 0.7778\n",
      "Epoch 110/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.3947 - acc: 0.8021 - val_loss: 0.5147 - val_acc: 0.7778\n",
      "Epoch 111/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3652 - acc: 0.8182 - val_loss: 0.5137 - val_acc: 0.7778\n",
      "Epoch 112/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3653 - acc: 0.8235 - val_loss: 0.5130 - val_acc: 0.7778\n",
      "Epoch 113/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3806 - acc: 0.8396 - val_loss: 0.5127 - val_acc: 0.7778\n",
      "Epoch 114/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.3548 - acc: 0.8396 - val_loss: 0.5122 - val_acc: 0.7937\n",
      "Epoch 115/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3632 - acc: 0.7861 - val_loss: 0.5104 - val_acc: 0.7937\n",
      "Epoch 116/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.3678 - acc: 0.8021 - val_loss: 0.5089 - val_acc: 0.7937\n",
      "Epoch 117/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.4045 - acc: 0.7968 - val_loss: 0.5077 - val_acc: 0.7937\n",
      "Epoch 118/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.4342 - acc: 0.7540 - val_loss: 0.5058 - val_acc: 0.8095\n",
      "Epoch 119/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.3983 - acc: 0.8128 - val_loss: 0.5048 - val_acc: 0.8095\n",
      "Epoch 120/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.3657 - acc: 0.7968 - val_loss: 0.5045 - val_acc: 0.8254\n",
      "Epoch 121/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.3760 - acc: 0.8021 - val_loss: 0.5044 - val_acc: 0.8254\n",
      "Epoch 122/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.3419 - acc: 0.8930 - val_loss: 0.5045 - val_acc: 0.8413\n",
      "Epoch 123/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3573 - acc: 0.8503 - val_loss: 0.5046 - val_acc: 0.8413\n",
      "Epoch 124/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.3470 - acc: 0.8449 - val_loss: 0.5042 - val_acc: 0.8413\n",
      "Epoch 125/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3704 - acc: 0.8503 - val_loss: 0.5043 - val_acc: 0.8413\n",
      "Epoch 126/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3481 - acc: 0.8396 - val_loss: 0.5051 - val_acc: 0.8413\n",
      "Epoch 127/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.3489 - acc: 0.8342 - val_loss: 0.5057 - val_acc: 0.8413\n",
      "Epoch 128/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3757 - acc: 0.8021 - val_loss: 0.5057 - val_acc: 0.8254\n",
      "Epoch 129/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3575 - acc: 0.8128 - val_loss: 0.5067 - val_acc: 0.8254\n",
      "Epoch 130/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3984 - acc: 0.7914 - val_loss: 0.5082 - val_acc: 0.8254\n",
      "Epoch 131/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3323 - acc: 0.8556 - val_loss: 0.5088 - val_acc: 0.8254\n",
      "Epoch 132/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3406 - acc: 0.8342 - val_loss: 0.5088 - val_acc: 0.8095\n",
      "Epoch 133/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.3475 - acc: 0.8449 - val_loss: 0.5082 - val_acc: 0.8095\n",
      "Epoch 134/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.3596 - acc: 0.8342 - val_loss: 0.5073 - val_acc: 0.8095\n",
      "Epoch 135/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.3477 - acc: 0.8503 - val_loss: 0.5069 - val_acc: 0.8095\n",
      "Epoch 136/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.3191 - acc: 0.9037 - val_loss: 0.5059 - val_acc: 0.8095\n",
      "Epoch 137/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3065 - acc: 0.8663 - val_loss: 0.5052 - val_acc: 0.8095\n",
      "Epoch 138/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.3184 - acc: 0.8610 - val_loss: 0.5061 - val_acc: 0.8095\n",
      "Epoch 139/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.3010 - acc: 0.8770 - val_loss: 0.5069 - val_acc: 0.8095\n",
      "Epoch 140/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.3150 - acc: 0.8663 - val_loss: 0.5088 - val_acc: 0.8095\n",
      "Epoch 141/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3738 - acc: 0.8289 - val_loss: 0.5094 - val_acc: 0.8095\n",
      "Epoch 142/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.3234 - acc: 0.8984 - val_loss: 0.5105 - val_acc: 0.8095\n",
      "Epoch 143/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.2708 - acc: 0.8770 - val_loss: 0.5117 - val_acc: 0.8095\n",
      "Epoch 144/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.2904 - acc: 0.8663 - val_loss: 0.5134 - val_acc: 0.8095\n",
      "Epoch 145/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.3325 - acc: 0.8663 - val_loss: 0.5135 - val_acc: 0.8095\n",
      "Epoch 146/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.3098 - acc: 0.8663 - val_loss: 0.5148 - val_acc: 0.8095\n",
      "Epoch 147/290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 0s 37us/step - loss: 0.2954 - acc: 0.8396 - val_loss: 0.5166 - val_acc: 0.8095\n",
      "Epoch 148/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.2596 - acc: 0.8984 - val_loss: 0.5180 - val_acc: 0.8254\n",
      "Epoch 149/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3147 - acc: 0.8610 - val_loss: 0.5190 - val_acc: 0.8254\n",
      "Epoch 150/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.2993 - acc: 0.8556 - val_loss: 0.5200 - val_acc: 0.8254\n",
      "Epoch 151/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.2834 - acc: 0.8663 - val_loss: 0.5228 - val_acc: 0.8254\n",
      "Epoch 152/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2792 - acc: 0.9198 - val_loss: 0.5238 - val_acc: 0.8254\n",
      "Epoch 153/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.2568 - acc: 0.9144 - val_loss: 0.5238 - val_acc: 0.8254\n",
      "Epoch 154/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2757 - acc: 0.8984 - val_loss: 0.5243 - val_acc: 0.8254\n",
      "Epoch 155/290\n",
      "187/187 [==============================] - 0s 38us/step - loss: 0.3154 - acc: 0.8717 - val_loss: 0.5256 - val_acc: 0.8254\n",
      "Epoch 156/290\n",
      "187/187 [==============================] - 0s 31us/step - loss: 0.2917 - acc: 0.8984 - val_loss: 0.5260 - val_acc: 0.8254\n",
      "Epoch 157/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2741 - acc: 0.8930 - val_loss: 0.5272 - val_acc: 0.8254\n",
      "Epoch 158/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2928 - acc: 0.8877 - val_loss: 0.5295 - val_acc: 0.8254\n",
      "Epoch 159/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2707 - acc: 0.8717 - val_loss: 0.5321 - val_acc: 0.8254\n",
      "Epoch 160/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2972 - acc: 0.8556 - val_loss: 0.5337 - val_acc: 0.8254\n",
      "Epoch 161/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2414 - acc: 0.9198 - val_loss: 0.5357 - val_acc: 0.8254\n",
      "Epoch 162/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2742 - acc: 0.8663 - val_loss: 0.5372 - val_acc: 0.8254\n",
      "Epoch 163/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2796 - acc: 0.8663 - val_loss: 0.5389 - val_acc: 0.8254\n",
      "Epoch 164/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2501 - acc: 0.9037 - val_loss: 0.5416 - val_acc: 0.8254\n",
      "Epoch 165/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2969 - acc: 0.8610 - val_loss: 0.5445 - val_acc: 0.8254\n",
      "Epoch 166/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2647 - acc: 0.8877 - val_loss: 0.5458 - val_acc: 0.8254\n",
      "Epoch 167/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2717 - acc: 0.8717 - val_loss: 0.5452 - val_acc: 0.8254\n",
      "Epoch 168/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.3307 - acc: 0.8449 - val_loss: 0.5465 - val_acc: 0.8254\n",
      "Epoch 169/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2724 - acc: 0.9091 - val_loss: 0.5482 - val_acc: 0.8254\n",
      "Epoch 170/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2933 - acc: 0.8663 - val_loss: 0.5504 - val_acc: 0.8254\n",
      "Epoch 171/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3322 - acc: 0.8449 - val_loss: 0.5507 - val_acc: 0.8254\n",
      "Epoch 172/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.3111 - acc: 0.8396 - val_loss: 0.5511 - val_acc: 0.8254\n",
      "Epoch 173/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2416 - acc: 0.9091 - val_loss: 0.5521 - val_acc: 0.8254\n",
      "Epoch 174/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2532 - acc: 0.8770 - val_loss: 0.5538 - val_acc: 0.8254\n",
      "Epoch 175/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2373 - acc: 0.9198 - val_loss: 0.5573 - val_acc: 0.8254\n",
      "Epoch 176/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2287 - acc: 0.9144 - val_loss: 0.5596 - val_acc: 0.8254\n",
      "Epoch 177/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2375 - acc: 0.8717 - val_loss: 0.5622 - val_acc: 0.8254\n",
      "Epoch 178/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2806 - acc: 0.8717 - val_loss: 0.5648 - val_acc: 0.8254\n",
      "Epoch 179/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2304 - acc: 0.9305 - val_loss: 0.5670 - val_acc: 0.8254\n",
      "Epoch 180/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2066 - acc: 0.9251 - val_loss: 0.5695 - val_acc: 0.8254\n",
      "Epoch 181/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2368 - acc: 0.8984 - val_loss: 0.5717 - val_acc: 0.8254\n",
      "Epoch 182/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2414 - acc: 0.9144 - val_loss: 0.5719 - val_acc: 0.8254\n",
      "Epoch 183/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.2376 - acc: 0.9144 - val_loss: 0.5747 - val_acc: 0.8254\n",
      "Epoch 184/290\n",
      "187/187 [==============================] - 0s 35us/step - loss: 0.2334 - acc: 0.9198 - val_loss: 0.5769 - val_acc: 0.8254\n",
      "Epoch 185/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2313 - acc: 0.9305 - val_loss: 0.5811 - val_acc: 0.8254\n",
      "Epoch 186/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2494 - acc: 0.8930 - val_loss: 0.5827 - val_acc: 0.8254\n",
      "Epoch 187/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2229 - acc: 0.8984 - val_loss: 0.5839 - val_acc: 0.8254\n",
      "Epoch 188/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2094 - acc: 0.9091 - val_loss: 0.5858 - val_acc: 0.8254\n",
      "Epoch 189/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2159 - acc: 0.9198 - val_loss: 0.5886 - val_acc: 0.8254\n",
      "Epoch 190/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.2483 - acc: 0.9144 - val_loss: 0.5919 - val_acc: 0.8254\n",
      "Epoch 191/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2600 - acc: 0.8663 - val_loss: 0.5967 - val_acc: 0.8254\n",
      "Epoch 192/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2432 - acc: 0.9091 - val_loss: 0.6032 - val_acc: 0.8254\n",
      "Epoch 193/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1882 - acc: 0.9198 - val_loss: 0.6094 - val_acc: 0.8254\n",
      "Epoch 194/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2605 - acc: 0.8930 - val_loss: 0.6154 - val_acc: 0.8254\n",
      "Epoch 195/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2124 - acc: 0.9091 - val_loss: 0.6212 - val_acc: 0.8254\n",
      "Epoch 196/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2346 - acc: 0.8984 - val_loss: 0.6273 - val_acc: 0.8254\n",
      "Epoch 197/290\n",
      "187/187 [==============================] - 0s 38us/step - loss: 0.2006 - acc: 0.9305 - val_loss: 0.6330 - val_acc: 0.8254\n",
      "Epoch 198/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2377 - acc: 0.8930 - val_loss: 0.6356 - val_acc: 0.8254\n",
      "Epoch 199/290\n",
      "187/187 [==============================] - 0s 38us/step - loss: 0.2169 - acc: 0.9091 - val_loss: 0.6373 - val_acc: 0.8254\n",
      "Epoch 200/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2118 - acc: 0.9091 - val_loss: 0.6387 - val_acc: 0.8254\n",
      "Epoch 201/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2324 - acc: 0.9037 - val_loss: 0.6411 - val_acc: 0.8254\n",
      "Epoch 202/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2380 - acc: 0.8984 - val_loss: 0.6455 - val_acc: 0.8254\n",
      "Epoch 203/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1907 - acc: 0.9412 - val_loss: 0.6494 - val_acc: 0.8254\n",
      "Epoch 204/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1977 - acc: 0.9198 - val_loss: 0.6532 - val_acc: 0.8254\n",
      "Epoch 205/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2155 - acc: 0.8877 - val_loss: 0.6549 - val_acc: 0.8254\n",
      "Epoch 206/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.2227 - acc: 0.8984 - val_loss: 0.6577 - val_acc: 0.8254\n",
      "Epoch 207/290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 0s 32us/step - loss: 0.2085 - acc: 0.9305 - val_loss: 0.6622 - val_acc: 0.8254\n",
      "Epoch 208/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2518 - acc: 0.8556 - val_loss: 0.6661 - val_acc: 0.8254\n",
      "Epoch 209/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2137 - acc: 0.9037 - val_loss: 0.6699 - val_acc: 0.8254\n",
      "Epoch 210/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2328 - acc: 0.8930 - val_loss: 0.6740 - val_acc: 0.8254\n",
      "Epoch 211/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2060 - acc: 0.9251 - val_loss: 0.6765 - val_acc: 0.8254\n",
      "Epoch 212/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2334 - acc: 0.9037 - val_loss: 0.6803 - val_acc: 0.8254\n",
      "Epoch 213/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2353 - acc: 0.8824 - val_loss: 0.6839 - val_acc: 0.8095\n",
      "Epoch 214/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2273 - acc: 0.8930 - val_loss: 0.6888 - val_acc: 0.8095\n",
      "Epoch 215/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2120 - acc: 0.9091 - val_loss: 0.6937 - val_acc: 0.8095\n",
      "Epoch 216/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2143 - acc: 0.9198 - val_loss: 0.6963 - val_acc: 0.8095\n",
      "Epoch 217/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2205 - acc: 0.9198 - val_loss: 0.6996 - val_acc: 0.8095\n",
      "Epoch 218/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2002 - acc: 0.9358 - val_loss: 0.7025 - val_acc: 0.8095\n",
      "Epoch 219/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.1942 - acc: 0.9144 - val_loss: 0.7057 - val_acc: 0.8095\n",
      "Epoch 220/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2079 - acc: 0.9305 - val_loss: 0.7105 - val_acc: 0.8095\n",
      "Epoch 221/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2123 - acc: 0.9198 - val_loss: 0.7146 - val_acc: 0.8095\n",
      "Epoch 222/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1802 - acc: 0.9572 - val_loss: 0.7192 - val_acc: 0.8095\n",
      "Epoch 223/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1552 - acc: 0.9358 - val_loss: 0.7216 - val_acc: 0.7937\n",
      "Epoch 224/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2111 - acc: 0.9037 - val_loss: 0.7250 - val_acc: 0.7937\n",
      "Epoch 225/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.2168 - acc: 0.9198 - val_loss: 0.7275 - val_acc: 0.8095\n",
      "Epoch 226/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2075 - acc: 0.9465 - val_loss: 0.7292 - val_acc: 0.8095\n",
      "Epoch 227/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1948 - acc: 0.9305 - val_loss: 0.7299 - val_acc: 0.8095\n",
      "Epoch 228/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2141 - acc: 0.9037 - val_loss: 0.7321 - val_acc: 0.8095\n",
      "Epoch 229/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1703 - acc: 0.9412 - val_loss: 0.7330 - val_acc: 0.8095\n",
      "Epoch 230/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2135 - acc: 0.9305 - val_loss: 0.7372 - val_acc: 0.8095\n",
      "Epoch 231/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1847 - acc: 0.9305 - val_loss: 0.7448 - val_acc: 0.8095\n",
      "Epoch 232/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1689 - acc: 0.9412 - val_loss: 0.7528 - val_acc: 0.8095\n",
      "Epoch 233/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1948 - acc: 0.9144 - val_loss: 0.7579 - val_acc: 0.7937\n",
      "Epoch 234/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1518 - acc: 0.9412 - val_loss: 0.7619 - val_acc: 0.7937\n",
      "Epoch 235/290\n",
      "187/187 [==============================] - 0s 38us/step - loss: 0.1608 - acc: 0.9412 - val_loss: 0.7660 - val_acc: 0.7937\n",
      "Epoch 236/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.1729 - acc: 0.9358 - val_loss: 0.7687 - val_acc: 0.7937\n",
      "Epoch 237/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.1827 - acc: 0.9465 - val_loss: 0.7709 - val_acc: 0.7937\n",
      "Epoch 238/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1679 - acc: 0.9412 - val_loss: 0.7694 - val_acc: 0.7937\n",
      "Epoch 239/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1805 - acc: 0.9358 - val_loss: 0.7688 - val_acc: 0.7937\n",
      "Epoch 240/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2050 - acc: 0.9144 - val_loss: 0.7678 - val_acc: 0.7937\n",
      "Epoch 241/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1879 - acc: 0.9305 - val_loss: 0.7702 - val_acc: 0.7937\n",
      "Epoch 242/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1703 - acc: 0.9626 - val_loss: 0.7762 - val_acc: 0.7937\n",
      "Epoch 243/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1901 - acc: 0.9412 - val_loss: 0.7817 - val_acc: 0.7937\n",
      "Epoch 244/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1534 - acc: 0.9358 - val_loss: 0.7880 - val_acc: 0.7937\n",
      "Epoch 245/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2192 - acc: 0.9305 - val_loss: 0.7909 - val_acc: 0.7937\n",
      "Epoch 246/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.2096 - acc: 0.9251 - val_loss: 0.7948 - val_acc: 0.7937\n",
      "Epoch 247/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1878 - acc: 0.9251 - val_loss: 0.7977 - val_acc: 0.7937\n",
      "Epoch 248/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1835 - acc: 0.9412 - val_loss: 0.8028 - val_acc: 0.7937\n",
      "Epoch 249/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1795 - acc: 0.9465 - val_loss: 0.8034 - val_acc: 0.7937\n",
      "Epoch 250/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1915 - acc: 0.9198 - val_loss: 0.8077 - val_acc: 0.7937\n",
      "Epoch 251/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1819 - acc: 0.9412 - val_loss: 0.8084 - val_acc: 0.7937\n",
      "Epoch 252/290\n",
      "187/187 [==============================] - 0s 43us/step - loss: 0.1616 - acc: 0.9572 - val_loss: 0.8162 - val_acc: 0.7937\n",
      "Epoch 253/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1661 - acc: 0.9358 - val_loss: 0.8182 - val_acc: 0.7937\n",
      "Epoch 254/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1657 - acc: 0.9626 - val_loss: 0.8202 - val_acc: 0.7937\n",
      "Epoch 255/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1683 - acc: 0.9465 - val_loss: 0.8296 - val_acc: 0.7937\n",
      "Epoch 256/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1965 - acc: 0.9198 - val_loss: 0.8301 - val_acc: 0.7937\n",
      "Epoch 257/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1476 - acc: 0.9679 - val_loss: 0.8308 - val_acc: 0.7937\n",
      "Epoch 258/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1659 - acc: 0.9358 - val_loss: 0.8327 - val_acc: 0.8095\n",
      "Epoch 259/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1709 - acc: 0.9305 - val_loss: 0.8342 - val_acc: 0.8095\n",
      "Epoch 260/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1419 - acc: 0.9679 - val_loss: 0.8484 - val_acc: 0.7937\n",
      "Epoch 261/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1760 - acc: 0.9412 - val_loss: 0.8509 - val_acc: 0.7937\n",
      "Epoch 262/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1394 - acc: 0.9626 - val_loss: 0.8505 - val_acc: 0.7937\n",
      "Epoch 263/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1528 - acc: 0.9519 - val_loss: 0.8511 - val_acc: 0.8095\n",
      "Epoch 264/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1474 - acc: 0.9572 - val_loss: 0.8529 - val_acc: 0.8095\n",
      "Epoch 265/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1540 - acc: 0.9519 - val_loss: 0.8581 - val_acc: 0.8095\n",
      "Epoch 266/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1509 - acc: 0.9519 - val_loss: 0.8645 - val_acc: 0.8095\n",
      "Epoch 267/290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 0s 32us/step - loss: 0.1663 - acc: 0.9412 - val_loss: 0.8686 - val_acc: 0.8095\n",
      "Epoch 268/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1435 - acc: 0.9519 - val_loss: 0.8741 - val_acc: 0.7937\n",
      "Epoch 269/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1606 - acc: 0.9412 - val_loss: 0.8787 - val_acc: 0.7937\n",
      "Epoch 270/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1337 - acc: 0.9519 - val_loss: 0.8813 - val_acc: 0.7937\n",
      "Epoch 271/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1021 - acc: 0.9786 - val_loss: 0.8829 - val_acc: 0.7937\n",
      "Epoch 272/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1375 - acc: 0.9733 - val_loss: 0.8846 - val_acc: 0.7937\n",
      "Epoch 273/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1160 - acc: 0.9840 - val_loss: 0.8867 - val_acc: 0.7937\n",
      "Epoch 274/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1550 - acc: 0.9305 - val_loss: 0.8883 - val_acc: 0.8095\n",
      "Epoch 275/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1456 - acc: 0.9626 - val_loss: 0.8934 - val_acc: 0.8095\n",
      "Epoch 276/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1842 - acc: 0.9305 - val_loss: 0.8977 - val_acc: 0.8095\n",
      "Epoch 277/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1582 - acc: 0.9358 - val_loss: 0.9021 - val_acc: 0.8095\n",
      "Epoch 278/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1781 - acc: 0.9305 - val_loss: 0.9064 - val_acc: 0.8095\n",
      "Epoch 279/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1682 - acc: 0.9358 - val_loss: 0.9127 - val_acc: 0.8095\n",
      "Epoch 280/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1606 - acc: 0.9519 - val_loss: 0.9164 - val_acc: 0.8095\n",
      "Epoch 281/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1317 - acc: 0.9679 - val_loss: 0.9193 - val_acc: 0.8095\n",
      "Epoch 282/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1254 - acc: 0.9679 - val_loss: 0.9223 - val_acc: 0.8095\n",
      "Epoch 283/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1451 - acc: 0.9679 - val_loss: 0.9247 - val_acc: 0.7937\n",
      "Epoch 284/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1672 - acc: 0.9412 - val_loss: 0.9251 - val_acc: 0.7937\n",
      "Epoch 285/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1645 - acc: 0.9465 - val_loss: 0.9246 - val_acc: 0.7937\n",
      "Epoch 286/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1537 - acc: 0.9412 - val_loss: 0.9230 - val_acc: 0.7937\n",
      "Epoch 287/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1659 - acc: 0.9412 - val_loss: 0.9242 - val_acc: 0.8095\n",
      "Epoch 288/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1338 - acc: 0.9626 - val_loss: 0.9270 - val_acc: 0.7937\n",
      "Epoch 289/290\n",
      "187/187 [==============================] - 0s 37us/step - loss: 0.1685 - acc: 0.9412 - val_loss: 0.9295 - val_acc: 0.8095\n",
      "Epoch 290/290\n",
      "187/187 [==============================] - 0s 32us/step - loss: 0.1490 - acc: 0.9412 - val_loss: 0.9338 - val_acc: 0.8095\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_dim=len(features)))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X1,y,batch_size=40, \n",
    "                    epochs=290, validation_split=0.25, shuffle=True, callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99982077],\n",
       "       [0.9287504 ],\n",
       "       [0.9977241 ],\n",
       "       ...,\n",
       "       [0.521169  ],\n",
       "       [1.        ],\n",
       "       [0.00320656]], dtype=float32)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('sample_submission (1).csv')\n",
    "result['target'] = predictions\n",
    "result.to_csv('submission11.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
